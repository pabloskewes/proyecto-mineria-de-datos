{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!rm -rf sample_data"
      ],
      "metadata": {
        "id": "J6s4Y4peYFv3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "KCEl5XX8uaVz"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "88lJFScfuaV1"
      },
      "outputs": [],
      "source": [
        "DATA_DIR = Path('./data').resolve()\n",
        "assert DATA_DIR.exists()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "back/core/processing.py"
      ],
      "metadata": {
        "id": "bPtYnuvdRhu0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "P5gKQtx8uaV2"
      },
      "outputs": [],
      "source": [
        "# Similar a read_json_course\n",
        "sample_json = json.loads((DATA_DIR / \"sample.json\").read_text())\n",
        "sample = pd.DataFrame.from_records(sample_json)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Enzb9PXeY-f4",
        "outputId": "5434ef75-feed-4247-dcee-90b53bc31616"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 300 entries, 67243 to 64515\n",
            "Data columns (total 12 columns):\n",
            " #   Column           Non-Null Count  Dtype \n",
            "---  ------           --------------  ----- \n",
            " 0   accept_language  300 non-null    object\n",
            " 1   agent            300 non-null    object\n",
            " 2   context          300 non-null    object\n",
            " 3   event            300 non-null    object\n",
            " 4   event_source     300 non-null    object\n",
            " 5   event_type       300 non-null    object\n",
            " 6   host             300 non-null    object\n",
            " 7   page             82 non-null     object\n",
            " 8   referer          300 non-null    object\n",
            " 9   session          300 non-null    object\n",
            " 10  time             300 non-null    object\n",
            " 11  username         300 non-null    object\n",
            "dtypes: object(12)\n",
            "memory usage: 38.6+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Al parecer el compressed sample no trae name ni ip\n",
        "# (columnas que si estan en el modelo de Django)\n",
        "def read_logs(df):\n",
        "    \"\"\" Read logs and expand inner JSON values\n",
        "\n",
        "    Recover valuable info\n",
        "\n",
        "    Arguments:\n",
        "        dataframe Pandas DataFrame\n",
        "    Returns:\n",
        "        expanded_records List of dictionnaries\n",
        "    \"\"\"\n",
        "    def add_if_available(row, field, subfield):\n",
        "        try:\n",
        "            return row[field][subfield]\n",
        "        except Exception:\n",
        "            return np.nan\n",
        "    df[\"context.course_id\"] = df.apply(\n",
        "        lambda x: add_if_available(x, \"context\", \"course_id\"), axis=1)\n",
        "    df[\"context.org_id\"] = df.apply(\n",
        "        lambda x: add_if_available(x, \"context\", \"org_id\"), axis=1)\n",
        "    df[\"context.path\"] = df.apply(\n",
        "        lambda x: add_if_available(x, \"context\", \"path\"), axis=1)\n",
        "    df[\"context.user_id\"] = df.apply(\n",
        "        lambda x: add_if_available(x, \"context\", \"user_id\"), axis=1)\n",
        "    # Note: extra values to be extracted should be added here\n",
        "    return df"
      ],
      "metadata": {
        "id": "BpdAhwnV0SU8"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_df = read_logs(sample)\n",
        "log_df = data_df[data_df.apply(lambda row: row[\"username\"] != '', axis=1)]\n",
        "log_df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmdWpyDT074k",
        "outputId": "7eb5d6ae-2289-4701-9711-039a68e891ab"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 300 entries, 67243 to 64515\n",
            "Data columns (total 16 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   accept_language    300 non-null    object \n",
            " 1   agent              300 non-null    object \n",
            " 2   context            300 non-null    object \n",
            " 3   event              300 non-null    object \n",
            " 4   event_source       300 non-null    object \n",
            " 5   event_type         300 non-null    object \n",
            " 6   host               300 non-null    object \n",
            " 7   page               82 non-null     object \n",
            " 8   referer            300 non-null    object \n",
            " 9   session            300 non-null    object \n",
            " 10  time               300 non-null    object \n",
            " 11  username           300 non-null    object \n",
            " 12  context.course_id  300 non-null    object \n",
            " 13  context.org_id     300 non-null    object \n",
            " 14  context.path       254 non-null    object \n",
            " 15  context.user_id    205 non-null    float64\n",
            "dtypes: float64(1), object(15)\n",
            "memory usage: 39.8+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stat: Videos (process_log_views)"
      ],
      "metadata": {
        "id": "y0ptIaLKR2mO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "back/views/tasks.py"
      ],
      "metadata": {
        "id": "gtOUyBlSR_9t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Funciones auxiliares para process_log_views\n",
        "def get_video_logs(course_data):\n",
        "        \"\"\"\n",
        "        From course logs, returns video type logs like play_video or stop_video\n",
        "        \"\"\"\n",
        "        video_event_type = [\n",
        "            'hide_transcript',\n",
        "            'load_video',\n",
        "            'pause_video',\n",
        "            'play_video',\n",
        "            'seek_video',\n",
        "            'show_transcript',\n",
        "            'speed_change_video',\n",
        "            'stop_video',\n",
        "            'video_hide_cc_menu',\n",
        "            'video_show_cc_menu',\n",
        "        ]\n",
        "        video_mobile_type = [\n",
        "            'edx.video.transcript.hidden',\n",
        "            'edx.video.loaded',\n",
        "            'edx.video.paused',\n",
        "            'edx.video.played',\n",
        "            'edx.video.position.changed',\n",
        "            'edx.video.transcript.shown',\n",
        "            'edx.video.stopped',\n",
        "        ]\n",
        "        raw_video_course_logs = course_data[course_data.event_type.isin(\n",
        "            video_event_type + video_mobile_type)]\n",
        "        return raw_video_course_logs"
      ],
      "metadata": {
        "id": "mcP_rt1W5Lce"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_logs_df = get_video_logs(log_df)"
      ],
      "metadata": {
        "id": "sxgz4wlCZxOR"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_segment_dataframe(grouped):\n",
        "        \"\"\"\n",
        "        Creates a dataframe with start-stop segment per user and video\n",
        "        \"\"\"\n",
        "        df_cols = ['id', 'username', 'time', 'start', 'end']\n",
        "        all_pairs = []\n",
        "        malformed_pairs = 0\n",
        "        for name, group in grouped:\n",
        "            state = {'id': None, 'init': None, 'action': None}\n",
        "            for index, row in group.iterrows():\n",
        "                etype = row.event_type\n",
        "                if etype == 'play_video':\n",
        "                    state['id'] = row.id\n",
        "                    state['init'] = row.currenttime\n",
        "                    state['action'] = row.event_type\n",
        "                elif etype == 'seek_forward':\n",
        "                    if state['id'] == row.id:\n",
        "                        # skip segment\n",
        "                        # all_pairs.append\n",
        "                        if state['action'] == 'play_video':\n",
        "                            try:\n",
        "                                assert (row.old <= row.new)\n",
        "                                all_pairs.append((row.id, row.username,\n",
        "                                                  row.time, row.old, row.new))\n",
        "                            except AssertionError:\n",
        "                                malformed_pairs += 1\n",
        "\n",
        "                    state['id'] = row.id\n",
        "                    state['init'] = row.currenttime\n",
        "                    state['action'] = row.event_type\n",
        "                elif etype == 'seek_back':\n",
        "                    if state['id'] == row.id and state[\n",
        "                            'action'] == 'play_video':\n",
        "                        try:\n",
        "                            assert (state['init'] <= row.old)\n",
        "                            all_pairs.append((row.id, row.username, row.time,\n",
        "                                              state['init'], row.old))\n",
        "                        except AssertionError:\n",
        "                            malformed_pairs += 1\n",
        "\n",
        "                    state['id'] = row.id\n",
        "                    state['init'] = row.currenttime\n",
        "                    state['action'] = row.event_type\n",
        "                elif etype == 'pause_video' or etype == 'stop_video':\n",
        "                    if state['id'] == row.id and state[\n",
        "                            'action'] == 'play_video':\n",
        "                        try:\n",
        "                            assert (state['init'] <= row.currenttime)\n",
        "                            all_pairs.append((row.id, row.username, row.time,\n",
        "                                              state['init'], row.currenttime))\n",
        "                        except AssertionError:\n",
        "                            malformed_pairs += 1\n",
        "                    state['id'] = row.id\n",
        "                    state['init'] = row.currenttime\n",
        "                    state['action'] = row.event_type\n",
        "                else:\n",
        "                    continue\n",
        "        print(\"Malformed pairs processed: {}\".format(malformed_pairs))\n",
        "        segments_df = pd.DataFrame(all_pairs, columns=df_cols)\n",
        "        return segments_df"
      ],
      "metadata": {
        "id": "ygde9MOxZmE0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "back/views/processing.py"
      ],
      "metadata": {
        "id": "j11I2QS1SGmt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Funciones auxiliares para process_views\n",
        "pps_videore = re.compile(\n",
        "    r'((?<=\"duration\": )[0-9.]+?(?=,|}))|((?<=\"code\": \").*?(?=\"))|((?<=\"id\": \").*?(?=\"))|((?<=\"currentTime\": )[0-9.]+?(?=,|}))'\n",
        ")\n",
        "load_videore = re.compile(\n",
        "    r'((?<=\"duration\": )[0-9.]+?(?=,|}))|((?<=\"code\": \").*?(?=\"))|((?<=\"id\": \").*?(?=\"))'\n",
        ")\n",
        "seek_videore = re.compile(\n",
        "    r'((?<=\"code\": \").*?(?=\"))|((?<=\"new_time\": )[0-9.]+?(?=,|}))|((?<=\"old_time\": )[0-9.]+?(?=,|}))|((?<=\"duration\": )[0-9.]+?(?=,|}))|((?<=\"type\": \").*?(?=\"))|((?<=\"id\": \").*?(?=\"))'\n",
        ")\n",
        "speedchange_videore = re.compile(\n",
        "    r'((?<=\"current_time\": )[0-9.]+?(?=,|}))|((?<=\"old_speed\": \")[0-9.]+?(?=\"))|((?<=\"code\": \").*?(?=\"))|((?<=\"new_speed\": \")[0-9.]+?(?=\"))|((?<=\"duration\": )[0-9.]+?(?=,|}))|((?<=\"id\": \").*?(?=\"))'\n",
        ")\n",
        "\n",
        "\n",
        "def reduce_to_tuple(groupTuples):\n",
        "    \"\"\"\n",
        "    Reduce an array of tuples to a single tuple\n",
        "    Eg: [(\"\",\"\",\"id\"),(\"duration\",\"\",\"\"),(\"\",\"code\",\"\")]\n",
        "        returns (\"duration\",\"code\",\"id\")\n",
        "    \"\"\"\n",
        "    data = np.array(groupTuples)\n",
        "    match = pd.DataFrame(data)\n",
        "    return tuple(match.sum(axis=0))\n",
        "\n",
        "def video_info_parser(row):\n",
        "    \"\"\"\n",
        "    Returns video id and its duration tuple from event column,\n",
        "    using only play, pause and stop type events\n",
        "    \"\"\"\n",
        "    etype = row.event_type\n",
        "    pps = ['play_video', 'pause_video', 'stop_video']\n",
        "    if etype in pps:\n",
        "        match = reduce_to_tuple(pps_videore.findall(row.event))\n",
        "        return match[2], float(match[0])\n",
        "    elif etype == 'load_video':\n",
        "        match = reduce_to_tuple(load_videore.findall(row.event))\n",
        "        return match[2], float(match[0])\n",
        "    elif etype == 'seek_video':\n",
        "        match = reduce_to_tuple(seek_videore.findall(row.event))\n",
        "        return match[5], float(match[3])\n",
        "    elif etype == 'speed_change_video':\n",
        "        match = reduce_to_tuple(speedchange_videore.findall(row.event))\n",
        "        return match[5], float(match[4])\n",
        "    else:\n",
        "        return\n",
        "\n",
        "\n",
        "def generate_video_dataframe(raw_video_data):\n",
        "    \"\"\"\n",
        "    From video type logs, catch videos into it and creates a dataframe\n",
        "    with its id and duration\n",
        "    \"\"\"\n",
        "    video_cols = ['id', 'duration']\n",
        "    video_tuples = []\n",
        "    for index, row in raw_video_data.iterrows():\n",
        "        video_tuples.append(video_info_parser(row))\n",
        "    all_video_df = pd.DataFrame(video_tuples,\n",
        "                                columns=video_cols).drop_duplicates()\n",
        "\n",
        "    return all_video_df"
      ],
      "metadata": {
        "id": "8g9EbViz6GvX"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "videos_df = generate_video_dataframe(video_logs_df)"
      ],
      "metadata": {
        "id": "6UJZz1IBaoEb"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def video_event_expander(row):\n",
        "    \"\"\"\n",
        "    Returns a tuple with video player info,\n",
        "    like where user started and stopped the video,\n",
        "    from event column using only play, pause and stop type events\n",
        "    \"\"\"\n",
        "    etype = row.event_type\n",
        "    pps = ['play_video', 'pause_video', 'stop_video']\n",
        "    if etype in pps:\n",
        "        match = reduce_to_tuple(pps_videore.findall(row.event))\n",
        "        return (row.username, row.time, row.event_type, match[2],\n",
        "                float(match[0]), float(match[3]), float(match[3]),\n",
        "                float(match[3]))\n",
        "\n",
        "    elif etype == 'load_video':\n",
        "        match = reduce_to_tuple(load_videore.findall(row.event))\n",
        "        return (row.username, row.time, row.event_type, match[2],\n",
        "                float(match[0]), -1, -1, -1)\n",
        "\n",
        "    elif etype == 'seek_video':\n",
        "        match = reduce_to_tuple(seek_videore.findall(row.event))\n",
        "        old = float(match[2])\n",
        "        new = float(match[1])\n",
        "        # Seek video forward\n",
        "        if old < new:\n",
        "            return (row.username, row.time, 'seek_forward', match[5],\n",
        "                    float(match[3]), new, old, new)\n",
        "        # Seek video backward\n",
        "        elif old > new:\n",
        "            return (row.username, row.time, 'seek_back', match[5],\n",
        "                    float(match[3]), new, old, new)\n",
        "        else:\n",
        "            return (row.username, row.time, 'seek_equal', match[5],\n",
        "                    float(match[3]), new, old, new)\n",
        "    elif etype == 'speed_change_video':\n",
        "        match = reduce_to_tuple(speedchange_videore.findall(row.event))\n",
        "        old = float(match[1])\n",
        "        new = float(match[3])\n",
        "        if old < new:  # Speed increased\n",
        "            return (row.username, row.time, 'speed_change_up', match[5],\n",
        "                    float(match[4]), float(match[0]), old, new)\n",
        "        elif old > new:  # Speed decreased\n",
        "            return (row.username, row.time, 'speed_change_down', match[5],\n",
        "                    float(match[4]), float(match[0]), old, new)\n",
        "        else:\n",
        "            return (row.username, row.time, 'speed_change_equal', match[5],\n",
        "                    float(match[4]), float(match[0]), old, new)\n",
        "\n",
        "    else:\n",
        "        return\n",
        "\n",
        "\n",
        "def expand_event_info(video_logs):\n",
        "    \"\"\"\n",
        "    From video type logs, creates a dataframe\n",
        "    with expanded video player info,\n",
        "    initially contained in the event column\n",
        "    \"\"\"\n",
        "    dframe_cols = [\n",
        "        'username', 'time', 'event_type', 'id', 'duration', 'currenttime',\n",
        "        'old', 'new'\n",
        "    ]\n",
        "    extend_video_tuples = []\n",
        "    for index, row in video_logs.iterrows():\n",
        "        extend_video_tuples.append(video_event_expander(row))\n",
        "    extend_video_logs = pd.DataFrame(extend_video_tuples, columns=dframe_cols)\n",
        "    return extend_video_logs"
      ],
      "metadata": {
        "id": "H1Jigz0Uamuf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "back/views/tasks.py"
      ],
      "metadata": {
        "id": "GwOq9BcxSMjs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Funcion auxiliar para process_log_views\n",
        "def process_views(dataframe):\n",
        "  # original process_views :: dataframe course_df date course_id code -> Django models\n",
        "        cols_to_use = ['username', 'time', 'event_type', 'event']\n",
        "        raw_video_course_logs = get_video_logs(dataframe[cols_to_use])\n",
        "        videos_in_logs = generate_video_dataframe(raw_video_course_logs) # videos en el curso\n",
        "        # course_id_df = course_df[\"course\"][0]\n",
        "\n",
        "        extend_video_logs = expand_event_info(raw_video_course_logs) #\n",
        "        sort_video_logs = extend_video_logs[\n",
        "            extend_video_logs.event_type != 'load_video'].copy()\n",
        "        sort_video_logs['time'] = pd.to_datetime(sort_video_logs['time'],\n",
        "                                                 unit='ns')\n",
        "        sort_video_logs.sort_values('time', inplace=True)\n",
        "        grouped_logs = sort_video_logs.groupby('username')\n",
        "        segments_df = make_segment_dataframe(grouped_logs) # segmentos de video vistos\n",
        "        views_df = segments_df[['id', 'username']].drop_duplicates() # visitas a los videos\n",
        "        return [videos_in_logs, segments_df, views_df]"
      ],
      "metadata": {
        "id": "eIVGEtTY5yNT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "back/core/processing.py"
      ],
      "metadata": {
        "id": "pD596YQWSb6Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Funcion auxiliar para process_logs_single_course\n",
        "def filter_course_team(logs, user_field_name='username', other_people=None):\n",
        "    \"\"\"Keeps the users that are not part of the course team\n",
        "\n",
        "    Arguments:\n",
        "        logs {pandas.core.frame.DataFrame} -- DataFrame to filter\n",
        "\n",
        "    Keyword Arguments:\n",
        "        user_field_name {str} -- name of the user name field  (default: {'username'})\n",
        "        other_people {list} -- people known to be part of the course/page team (default: {None})\n",
        "\n",
        "    Returns:\n",
        "        pandas.core.frame.DataFrame -- [description]\n",
        "    \"\"\"\n",
        "    def bool_regex(x):\n",
        "        rgx = re.compile(r'.*(studio|instructor).*')\n",
        "        if rgx.match(x) != None:\n",
        "            return 1\n",
        "        else:\n",
        "            return 0\n",
        "\n",
        "    users_and_etypes = logs[[user_field_name, 'event_type']].copy()\n",
        "    users_and_etypes['event_type'] = users_and_etypes['event_type'].apply(\n",
        "        bool_regex)\n",
        "    users_and_profes = users_and_etypes.groupby(user_field_name).sum().reset_index()\\\n",
        "        .sort_values('event_type', ascending=False)\n",
        "    students = users_and_profes[users_and_profes.event_type ==\n",
        "                                0][user_field_name]\n",
        "\n",
        "    if other_people is not None:\n",
        "        students = students[~students.isin(other_people)]\n",
        "\n",
        "    return logs[logs.username.isin(students)]\n",
        "\n",
        "def filter_by_log_qty(logs, min_logs=15, user_field_name='username'):\n",
        "    \"\"\"Keeps the users with more than min_logs logs in the course\n",
        "\n",
        "    Arguments:\n",
        "        logs {pandas.core.frame.DataFrame} -- DataFrame to filter\n",
        "\n",
        "    Keyword Arguments:\n",
        "        min_logs {int} -- min quantity of logs to stay in the df (default: {15})\n",
        "        user_field_name {str} -- name of the user name field (default: {'username'})\n",
        "\n",
        "    Returns:\n",
        "        pandas.core.frame.DataFrame -- [description]\n",
        "    \"\"\"\n",
        "    users_count = logs.groupby([user_field_name])[user_field_name]\\\n",
        "        .count()\\\n",
        "        .to_frame()\\\n",
        "        .rename(columns={user_field_name: 'count'})\\\n",
        "        .reset_index()\n",
        "    active_users = users_count[users_count['count']\n",
        "                               > min_logs][user_field_name]\n",
        "    return logs[logs.username.isin(active_users)]"
      ],
      "metadata": {
        "id": "zOu7H50S0k8X"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import timedelta, datetime, date\n",
        "# Task para crear estadisticas entorno a videos\n",
        "# Crea videos, cantidad de visitas, segmentos vistos del video\n",
        "def process_log_views(end_date=None, day_window=None, run_code=None, course=None):\n",
        "  #originalmente llama a process_logs_single_course(process_views, \"views\", course, end_date, day_window, run_code)\n",
        "\n",
        "  #time_window = DAY_WINDOW if day_window is None else day_window\n",
        "  time_window = None\n",
        "  #tz = pytz.timezone(settings.TIME_ZONE)\n",
        "  #end_date_localized = None if end_date is None else tz.localize(end_date)\n",
        "  end_date_localized = None\n",
        "  #staff_users = StaffUserName.objects.all()\n",
        "  staff_users = []\n",
        "\n",
        "  # course_logs = Log.objects.filter(time__gte=(end_date_localized - time_window),\n",
        "  #                                  time__lt=(end_date_localized),\n",
        "  #                                  course_id=course_id\n",
        "  #                                  ).values('username', 'event_type', 'name', 'referer', 'time', 'event', 'course_id', 'org_id', 'user_id', 'path', 'page')\n",
        "  course_logs =\n",
        "  if course_logs.count() == 0:\n",
        "        return\n",
        "  logs_full = pd.DataFrame(course_logs)\n",
        "\n",
        "  users = [u.username for u in staff_users], filter_by_log_qty\n",
        "\n",
        "  logs = filter_course_team(logs_full, other_people=users)\n",
        "\n",
        "  day_logs = logs[logs.time.dt.date == period]\n",
        "\n",
        "  periods = pd.date_range(start=end_date_localized - time_window,\n",
        "                            end=end_date_localized, freq=timedelta(days=1), tz=settings.TIME_ZONE)\n",
        "  for period in periods:\n",
        "        day_logs = logs[logs.time.dt.date == period]\n",
        "        # Continue if no logs exists\n",
        "        count, _ = day_logs.shape\n",
        "        if count == 0:\n",
        "            continue\n",
        "        #procedure(day_logs, course_dataframe, period, course_id, run_code)\n",
        "        process_views(day_logs)\n",
        ""
      ],
      "metadata": {
        "id": "-uBH2uH64ck3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}